---
title: "On the waning of forms - a corpus-based analysis of losers in language change (Part 3)"
author: "Martin Schweinberger"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---

```{r uq1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("https://slcladal.github.io/images/isle6.png")
```


This document documents the analysis of the adjective amplifier *very* in New Zealand English. The analysis was performed with the aim of fitting a generalized-linear binomial logistic mixed-effects regression to explain which factors correlate with the use of *very* and to ascertain if 

1. *very* is decreasing across apparent time 

2. if the decrease of *very* is systematic or layered (which would imply that the use of very is stratified along linguistic and social lines) or unsystematic (which would imply that it correlates with few if any linguistic or social variables). 

# Introduction

We will now begin with the analysis. In a first step, the session is prepared by setting options and activating packages.

```{r verynze_01, message=FALSE, warning=FALSE}
# load packages
library(tidyverse)
library(tidyr)
# set options
options(stringsAsFactors = F)
options(scipen = 999)
options(max.print=10000)
```

We proceed by loading the data, factorizing variables that are so far represented as character strings instead of factors, and inspecting its characteristics.

```{r verynze_02, message=FALSE, warning=FALSE}
# load data
verywsc <- read.delim(here::here("data", "ampwsc_regdat.txt"), sep = "\t", header = T, skipNul = T)
# remove superfluous variables
verywsc <- verywsc %>%
  dplyr::select(-ID, - FileSpeaker, -Speaker, -File, -Age_original) %>%
  dplyr::mutate_if(is.character, factor)
# inspect data
nrow(verywsc); str(verywsc); head(verywsc); summary (verywsc)
```

We will now scale numeric variables so that the estimates refer to the mean of the numeric variables rather than their true 0-point. This is necessary as estimates for adjectives that occur with a frequency of 0 are nonsensical.

```{r verynze_03, message=FALSE, warning=FALSE}
# frequency
summary(verywsc$Frequency)
verywsc <- verywsc %>%
  dplyr::mutate(Frequency  = scale(Frequency)) %>%
  dplyr::mutate(Frequency = as.vector(Frequency))
# inspect
summary(verywsc$Frequency)
```

We plot the scaled variable (Frequency).

```{r verynze_04, message=FALSE, warning=FALSE}
plot(verywsc$Frequency)
```

We also scale gradability and plot the resulting scaled gradability.

```{r verynze_05, message=FALSE, warning=FALSE}
# gradability
verywsc$Gradability <- as.vector(scale(verywsc$Gradability-1))
summary(verywsc$Gradability)

plot(verywsc$Gradability, verywsc$very)
abline(lm(verywsc$very ~ verywsc$Gradability))
```

# Boruta

We now begin with the modeling. In a first step, we use a Boruta analysis as a variable selection procedure to determine which variables have any sort of meaningful relationship with the dependent variable. We will only consider variables which have been deemed as being important during the model fitting process.

```{r verynze_06, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# create data for boruta
borutadata <- verywsc %>%
  na.omit()
# save and load data
write.table(borutadata, here::here("data", "borutadata.txt"), sep = "\t", 
            col.names = T, row.names = F, quote = F)
# run 1
set.seed(2019121201)
boruta1 <- Boruta(very ~.,data=borutadata)
print(boruta1)
```

As Function is deemed unimportant, we remove it from the analysis and rerun the variable selection procedure.

We now begin with the modelling. In a first step, we use a Boruta analysis as a variable selection procedure to determine which variables have any sort of meaningful relationship with the dependent variable.

```{r verynze_07, message=FALSE, warning=FALSE}
rejected <- names(boruta1$finalDecision)[which(boruta1$finalDecision == "Rejected")]
# update data for boruta
borutadata <- borutadata %>%
  dplyr::select(-rejected)
# run 2
set.seed(2019121202)
boruta2 <- Boruta(very ~.,data=borutadata)
print(boruta2)
```

We also remove Education as it is deemed only tentatively important and start a 3^rd^ run.

```{r verynze_08, message=FALSE, warning=FALSE}
rejected <- names(boruta1$finalDecision)[which(boruta1$finalDecision == "Tentative")]
# update data for boruta
borutadata <- borutadata %>%
  dplyr::select(-rejected)
# run 3
set.seed(2019121203)
boruta3 <- Boruta(very ~., data=borutadata)
print(boruta3)
```

No more variables need to be removed. We now inspect the visualizations of the Boruta analysis. 

```{r verynze_09, message=FALSE, warning=FALSE}
plot(boruta3)
```

In addition, we inspect the history of the Boruta runs. 

```{r verynze_10, message=FALSE, warning=FALSE}
plotImpHistory(boruta3)
```

Now, we create the final publication visualization of the Boruta analysis. 

```{r verynze_11, message=FALSE, warning=FALSE}
borutadf <- as.data.frame(boruta3$ImpHistory) %>%
  gather(Variable, Importance, Adjective:shadowMin) %>%
  mutate(Type = ifelse(str_detect(Variable, "shadow"), "Control", "Predictor")) %>%
  mutate(Type = factor(Type),
         Variable = factor(Variable))
ggplot(borutadf, aes(x = reorder(Variable, Importance, mean), y = Importance, fill = Type)) + 
  geom_boxplot() +
  geom_vline(xintercept=3.5, linetype="dashed", color = "black") +
  scale_fill_manual(values = c("gray80", "gray40")) +
  theme_bw() + 
  theme(legend.position = "top",
        axis.text.x = element_text(angle=90)) +
  labs(x = "Variable") +
  ggsave(file =  here::here("images", "Boruta.png"), 
         width = 15, height = 10, units = c("cm"),  dpi = 600)
```

Potentially relevant predictors are:

* Age
* SemanticCategory
* Adjective
* Frequency
* Emotionality
* Ethnicity
* Priming
* Gradability
* L1

# Mixed-Effects Model

We begin with the model fitting by setting options and creating intercept-only base-line models. 

```{r verynze_12, message=FALSE, warning=FALSE}
# load library
library(rms)
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
verywsc.dist <- datadist(verywsc)
options(datadist = "verywsc.dist")
# generate initial minimal regression model 
m0.glm = glm(very ~ 1, family = binomial, data = verywsc) 
# inspect results
summary(m0.glm)
```

In a next step, we cerate analogous base-line models with Adjective as a random effect (random intercepts). 

```{r verynze_13, message=FALSE, warning=FALSE}
# load packages
library(lme4)
library(car)
# create model with a random intercept for Adjective
m0.glmer = glmer(very ~ (1|Adjective), data = verywsc, family = binomial)
```

We can now use the AIC to determine if including a random effect structure is justified. 

```{r verynze_14, message=FALSE, warning=FALSE}
aic.glmer <- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

The AIC of the glmer object is substantially smaller which indicates that including the random intercepts appears to be justified. 

## Model fitting{-}

#### Age {-}

```{r verynze_16, message=FALSE, warning=FALSE}
#	manual modelfitting
m0.glmer <- glmer(very ~ 1 + (1|Adjective), family = binomial, data = verywsc, 
                  control=glmerControl(optimizer="bobyqa"))
# add Age
ifelse(min(ftable(verywsc$Age, verywsc$very)) == 0, "not possible", "possible")
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m0.glmer, m1.glmer, test = "Chi")
Anova(m1.glmer, type = "III", test = "Chi")
```

#### Semantic Category{-}

```{r verynze_17, message=FALSE, warning=FALSE}
m2.glmer <- update(m1.glmer, .~.+ SemanticCategory)
car::vif(m2.glmer)
anova(m2.glmer, m1.glmer, test = "Chi")  
Anova(m2.glmer, type = "III", test = "Chi") 
```

#### Frequency {-}

```{r verynze_17, message=FALSE, warning=FALSE}
# add Frequency
m3.glmer <- update(m1.glmer, .~.+ Frequency)
car::vif(m3.glmer)
anova(m3.glmer, m1.glmer, test = "Chi")  
```

#### Emotionality{-}

```{r verynze_18a, message=FALSE, warning=FALSE}
# add Emotionality
ifelse(min(ftable(verywsc$Emotionality, verywsc$very)) == 0, "not possible", "possible")
m4.glmer <- update(m1.glmer, .~.+Emotionality)
car::vif(m4.glmer)
anova(m4.glmer, m1.glmer, test = "Chi")              
Anova(m4.glmer, type = "III", test = "Chi")        
```

#### Ethnicity{-}

```{r verynze_19, message=FALSE, warning=FALSE}
ifelse(min(ftable(verywsc$Ethnicity, verywsc$very)) == 0, "not possible", "possible")
m5.glmer <- update(m4.glmer, .~.+Ethnicity)
car::vif(m5.glmer)
anova(m5.glmer, m4.glmer, test = "Chi")       
```

#### Priming{-}

```{r verynze_20, message=FALSE, warning=FALSE}
ifelse(min(ftable(verywsc$Priming, verywsc$very)) == 0, "not possible", "possible")
m6.glmer <- update(m4.glmer, .~.+Priming)
car::vif(m6.glmer)
anova(m6.glmer, m4.glmer, test = "Chi")     
```

#### Gradability {-}

```{r verynze_21, message=FALSE, warning=FALSE}
# add Gradability
m7.glmer <- update(m4.glmer, .~.+Gradability)
car::vif(m6.glmer)
anova(m7.glmer, m4.glmer, test = "Chi")    
Anova(m7.glmer, type = "III", test = "Chi")  
```

#### L1{-}

```{r verynze_22, message=FALSE, warning=FALSE}
ifelse(min(ftable(verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
m8.glmer <- update(m7.glmer, .~.+L1)
max(car::vif(m8.glmer)[,1])
anova(m8.glmer, m7.glmer, test = "Chi")  
```

## Interactions{-}

```{r verynze_24, message=FALSE, warning=FALSE}
# find all 2-way interactions
library(utils)
#colnames(verywsc) # remove # to activate
vars <- c("Age",  "SemanticCategory", "Frequency", 
          "Emotionality",  "Ethnicity", "Priming",
          "Gradability", "L1")
intac <- t(combn(vars, 2))
intac
```

#### Check fro incomplete information{-}

```{r}
m9.tb <- ifelse(min(ftable(verywsc$Age, verywsc$SemanticCategory, verywsc$very)) == 0, "not possible", "possible")
#m10.tb <- ifelse(min(ftable(verywsc$Age, verywsc$Frequency, verywsc$very)) == 0, "not possible", "possible")
m11.tb <- ifelse(min(ftable(verywsc$Age, verywsc$Emotionality, verywsc$very)) == 0, "not possible", "possible")
m12.tb <- ifelse(min(ftable(verywsc$Age, verywsc$Ethnicity, verywsc$very)) == 0, "not possible", "possible")
m13.tb <- ifelse(min(ftable(verywsc$Age, verywsc$Priming, verywsc$very)) == 0, "not possible", "possible")
#m14.tb <- ifelse(min(ftable(verywsc$Age, verywsc$Gradability, verywsc$very)) == 0, "not possible", "possible")
m15.tb <- ifelse(min(ftable(verywsc$Age, verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
#m16.tb <- ifelse(min(ftable(verywsc$SemanticCategory, verywsc$Frequency, verywsc$very)) == 0, "not possible", "possible")
m17.tb <- ifelse(min(ftable(verywsc$SemanticCategory, verywsc$Emotionality, verywsc$very)) == 0, "not possible", "possible")
m18.tb <- ifelse(min(ftable(verywsc$SemanticCategory, verywsc$Ethnicity, verywsc$very)) == 0, "not possible", "possible")
m19.tb <- ifelse(min(ftable(verywsc$SemanticCategory, verywsc$Priming, verywsc$very)) == 0, "not possible", "possible")
#m20.tb <- ifelse(min(ftable(verywsc$SemanticCategory, verywsc$Gradability, verywsc$very)) == 0, "not possible", "possible")
m21.tb <- ifelse(min(ftable(verywsc$SemanticCategory, verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
#m22.tb <- ifelse(min(ftable(verywsc$Frequency, verywsc$Emotionality, verywsc$very)) == 0, "not possible", "possible")
#m23.tb <- ifelse(min(ftable(verywsc$Frequency, verywsc$Ethnicity, verywsc$very)) == 0, "not possible", "possible")
#m24.tb <- ifelse(min(ftable(verywsc$Frequency, verywsc$Priming, verywsc$very)) == 0, "not possible", "possible")
#m25.tb <- ifelse(min(ftable(verywsc$Frequency, verywsc$Gradability, verywsc$very)) == 0, "not possible", "possible")
#m26.tb <- ifelse(min(ftable(verywsc$Frequency, verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
m27.tb <- ifelse(min(ftable(verywsc$Emotionality, verywsc$Ethnicity, verywsc$very)) == 0, "not possible", "possible")
m28.tb <- ifelse(min(ftable(verywsc$Emotionality, verywsc$Priming, verywsc$very)) == 0, "not possible", "possible")
#m29.tb <- ifelse(min(ftable(verywsc$Emotionality, verywsc$Gradability, verywsc$very)) == 0, "not possible", "possible")
m30.tb <- ifelse(min(ftable(verywsc$Emotionality, verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
m31.tb <- ifelse(min(ftable(verywsc$Ethnicity, verywsc$Priming, verywsc$very)) == 0, "not possible", "possible")
#m32.tb <- ifelse(min(ftable(verywsc$Ethnicity, verywsc$Gradability, verywsc$very)) == 0, "not possible", "possible")
m33.tb <- ifelse(min(ftable(verywsc$Ethnicity, verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
#m34.tb <- ifelse(min(ftable(verywsc$Priming, verywsc$Gradability, verywsc$very)) == 0, "not possible", "possible")
m35.tb <- ifelse(min(ftable(verywsc$Priming, verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
#m36.tb <- ifelse(min(ftable(verywsc$Gradability, verywsc$L1, verywsc$very)) == 0, "not possible", "possible")
```



```{r}
m9.tb 
#m10.tb # possible 
m11.tb # possible 
m12.tb 
m13.tb # possible
#m14.tb  # possible  
m15.tb 
#m16.tb # possible  
m17.tb 
m18.tb 
m19.tb 
#m20.tb # possible  
m21.tb 
#m22.tb # possible  
#m23.tb # possible  
#m24.tb # possible  
#m25.tb # possible  
#m26.tb # possible  
m27.tb # possible
m28.tb # possible
#m29.tb # possible  
m30.tb # possible
m31.tb # possible
#m32.tb # possible  
m33.tb # possible
#m34.tb # possible  
m35.tb # possible
#m36.tb # possible  
```

#### Generate models{-}

```{r verynze_25, message=FALSE, warning=FALSE}
#m9.glmer <- update(m7.glmer, .~.+ Age * SemanticCategory)
m10.glmer <- update(m7.glmer, .~.+ Age * Frequency)
m11.glmer <- update(m7.glmer, .~.+ Age * Emotionality)
#m12.glmer <- update(m7.glmer, .~.+ Age * Ethnicity)
m13.glmer <- update(m7.glmer, .~.+ Age * Priming)
m14.glmer <- update(m7.glmer, .~.+ Age * Gradability)
#m15.glmer <- update(m7.glmer, .~.+ Age * L1)
m16.glmer <- update(m7.glmer, .~.+ SemanticCategory * Frequency)
#m17.glmer <- update(m7.glmer, .~.+ SemanticCategory * Emotionality)
#m18.glmer <- update(m7.glmer, .~.+ SemanticCategory * Ethnicity)
#m19.glmer <- update(m7.glmer, .~.+ SemanticCategory * Priming)
m20.glmer <- update(m7.glmer, .~.+ SemanticCategory * Gradability)
#m21.glmer <- update(m7.glmer, .~.+ SemanticCategory * L1)
m22.glmer <- update(m7.glmer, .~.+ Frequency * Emotionality)
m23.glmer <- update(m7.glmer, .~.+ Frequency * Ethnicity)
m24.glmer <- update(m7.glmer, .~.+ Frequency * Priming)
m25.glmer <- update(m7.glmer, .~.+ Frequency * Gradability)
m26.glmer <- update(m7.glmer, .~.+ Frequency * L1)
m27.glmer <- update(m7.glmer, .~.+ Emotionality * Ethnicity)
m28.glmer <- update(m7.glmer, .~.+ Emotionality * Priming)
m29.glmer <- update(m7.glmer, .~.+ Emotionality * Gradability)
m30.glmer <- update(m7.glmer, .~.+ Emotionality * L1)
m31.glmer <- update(m7.glmer, .~.+ Ethnicity * Priming)
m32.glmer <- update(m7.glmer, .~.+ Ethnicity * Gradability)
m33.glmer <- update(m7.glmer, .~.+ Ethnicity * L1)
m34.glmer <- update(m7.glmer, .~.+ Priming * Gradability)
m35.glmer <- update(m7.glmer, .~.+ Priming * L1)
m36.glmer <- update(m7.glmer, .~.+ Gradability * L1) 
```

#### Check multicollinearity{-}

```{r}
#max(car::vif(m9.glmer)[,1])
max(car::vif(m10.glmer)[,1])
max(car::vif(m11.glmer)[,1])
#max(car::vif(m12.glmer)[,1])
max(car::vif(m13.glmer)[,1])
max(car::vif(m14.glmer)[,1])
#max(car::vif(m15.glmer)[,1])
max(car::vif(m16.glmer)[,1])
#max(car::vif(m17.glmer)[,1])
#max(car::vif(m18.glmer)[,1])
#max(car::vif(m19.glmer)[,1])
max(car::vif(m20.glmer)[,1])
#max(car::vif(m21.glmer)[,1])
max(car::vif(m22.glmer)[,1])
max(car::vif(m23.glmer)[,1]) # ok
max(car::vif(m24.glmer)[,1]) # ok
max(car::vif(m25.glmer)[,1]) # ok
max(car::vif(m26.glmer)[,1]) # ok
max(car::vif(m27.glmer)[,1])
max(car::vif(m28.glmer)[,1])
max(car::vif(m29.glmer)[,1])
max(car::vif(m30.glmer)[,1])
max(car::vif(m31.glmer)[,1])
max(car::vif(m32.glmer)[,1])
max(car::vif(m33.glmer)[,1])
max(car::vif(m34.glmer)[,1]) # ok
max(car::vif(m35.glmer)[,1]) # ok
max(car::vif(m36.glmer)[,1]) # ok
```

```{r verynze_22, message=FALSE, warning=FALSE}
anova(m23.glmer, m7.glmer, test = "Chi")  
```

```{r verynze_22, message=FALSE, warning=FALSE}
anova(m24.glmer, m7.glmer, test = "Chi")  
```

```{r verynze_22, message=FALSE, warning=FALSE}
anova(m25.glmer, m7.glmer, test = "Chi")  
```

```{r verynze_22, message=FALSE, warning=FALSE}
anova(m26.glmer, m7.glmer, test = "Chi")  
```

```{r verynze_22, message=FALSE, warning=FALSE}
anova(m34.glmer, m7.glmer, test = "Chi")  
```

```{r verynze_22, message=FALSE, warning=FALSE}
anova(m35.glmer, m7.glmer, test = "Chi")  
```

```{r verynze_22, message=FALSE, warning=FALSE}
anova(m36.glmer, m7.glmer, test = "Chi")  
```
We begin the diagnostics with visualizing residuals.

```{r verynze_100, message=FALSE, warning=FALSE}
par(mfrow = c(1, 4))   # display plots in 3 rows and 2 columns
plot(m7.glmer, col = "black", pch = 20); par(mfrow = c(1, 1))
```

## Model fitting summary{-}

```{r verynze_112, message=FALSE, warning=FALSE}
# load function for regression table summary
source("D:\\R/meblr.summary.R")
# set up summary table
meblrm_ampwsc <- meblrm.summary(m0.glm, m8.glm, m0.glmer, m8.glmer, verywsc$very) 
# save results to disc
write.table(meblrm_ampwsc, here::here("data", "meblrm_ampwsc.txt"), sep="\t")
# inspect result summary
meblrm_ampwsc
```


We also check the Anova summary to see if predictors, rather than individual predictor levels, are significant and to what extent.

```{r verynze_113, message=FALSE, warning=FALSE}
# load function
library(car)
meblrm_ampwsc_Anova <- Anova(m3.glmer, type = "III", test = "Chi")
# save results to disc
write.table(meblrm_ampwsc_Anova, "datatables/meblrm_ampwsc_Anova.txt", sep="\t")
# inspect results in Anova style
meblrm_ampwsc_Anova
```

We will also inspect the effects of the individual predcitors. We begin with Age.

```{r verynze_114, message=FALSE, warning=FALSE}
effectage <- anova(m1.glmer, m0.glmer, test = "Chi")
effectage
```

Now, we inspect the effects of Emotionality.

```{r verynze_115, message=FALSE, warning=FALSE}
effectemotionality <- anova(m3.glmer, m1.glmer, test = "Chi")
```

In a next step, we create a summary of the model fitting process.

```{r verynze_115, message=FALSE, warning=FALSE}
# use customized model comparison function
# create compariveryns
m1m0 <- anova(m0.glmer, m1.glmer, test = "Chi")
m2m1 <- anova(m2.glmer, m1.glmer, test = "Chi")
m3m1 <- anova(m3.glmer, m1.glmer, test = "Chi")
m4m3 <- anova(m4.glmer, m3.glmer, test = "Chi")
m5m3 <- anova(m5.glmer, m3.glmer, test = "Chi")
m6m3 <- anova(m6.glmer, m3.glmer, test = "Chi")
m7m3 <- anova(m7.glmer, m3.glmer, test = "Chi")
m8m3 <- anova(m8.glmer, m3.glmer, test = "Chi")
m11m3 <- anova(m11.glmer, m3.glmer, test = "Chi")
m14m3 <- anova(m14.glmer, m3.glmer, test = "Chi")
m18m3 <- anova(m18.glmer, m3.glmer, test = "Chi")
m20m3 <- anova(m20.glmer, m3.glmer, test = "Chi")
m27m3 <- anova(m27.glmer, m3.glmer, test = "Chi")
m28m3 <- anova(m28.glmer, m3.glmer, test = "Chi")
m29m3 <- anova(m29.glmer, m3.glmer, test = "Chi")
m30m3 <- anova(m30.glmer, m3.glmer, test = "Chi")
m31m3 <- anova(m31.glmer, m3.glmer, test = "Chi")
m34m3 <- anova(m34.glmer, m3.glmer, test = "Chi")
m35m3 <- anova(m35.glmer, m3.glmer, test = "Chi")
m36m3 <- anova(m36.glmer, m3.glmer, test = "Chi")
# create a list of the model compariveryns
mdlcmp <- list(m1m0, m2m1, m3m1, m4m3, m5m3, m6m3, m7m3, m8m3, 
               m11m3, m14m3, m18m3, m20m3, m27m3, m28m3, m29m3, 
               m30m3, m31m3, m34m3, m35m3, m36m3)
# load function
source("D:\\R/ModelFittingSummarySWSU.R") # for Mixed Effects Model fitting (step-wise step-up): Binary Logistic Mixed Effects Models
# apply function
mdl.cmp.glmersc.swsu.dm <- mdl.fttng.swsu(mdlcmp)
# save comparisons to disc
write.table(mdl.cmp.glmersc.swsu.dm, "datatables/mdl_cmp_glmersc_swsu_verywscnew.txt", sep="\t")
# inspect output
mdl.cmp.glmersc.swsu.dm
```

###Post-Hoc tests{-}

Age

```{r verynze_116, message=FALSE, warning=FALSE}
library (multcomp)
summary(glht(m8.glmer, mcp(Age="Tukey")))
```

Emotionality

```{r verynze_117, message=FALSE, warning=FALSE}
summary(glht(m8.glmer, mcp(Emotionality="Tukey")))
```

We now check the prediction accuracy of the final minimal model.

```{r verynze_118, message=FALSE, warning=FALSE}
# predict probs of nativelike for effects
verywsc$PredictedFrequency <- predict(m8.glmer, verywsc, type="response")
# create response variable
verywsc$PredictedResponse <- ifelse(verywsc$PredictedFrequency > .5, "very", "other")
#summary(verywscnew$PredictedResponse)
# load library
library(caret)
# create confusion matrix
confusionMatrix(as.factor(verywsc$PredictedResponse), as.factor(verywsc$very))
```



# Model summary

```{r dp2_04, message=F, warning=F}
sjPlot::tab_model(m0.glmer, m8.glmer)
```

```{r dp2_04, message=F, warning=F}
sjPlot::plot_model(m8.glmer, type = "pred", terms = c("Age")) +
  theme_bw() +
  theme(legend.position = "top",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black")) +
  scale_y_continuous(name = "Predicted Probabilty of VERY", 
                     limits = c(0, .5),
                     breaks = seq(0, .5, .20), 
                     labels = seq(0, .5, .20)) +
  labs(main = "") +
  ggsave(file =  here::here("images", "Effect_Age.png"), 
         width = 15, height = 10, units = c("cm"),  dpi = 600)
```

```{r dp2_04, message=F, warning=F}
sjPlot::plot_model(m8.glmer, type = "pred", terms = c("Emotionality")) +
  theme_bw() +
  theme(legend.position = "top",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black")) +
  scale_y_continuous(name = "Predicted Probabilty of VERY", 
                     limits = c(0, .5),
                     breaks = seq(0, .5, .20), 
                     labels = seq(0, .5, .20)) +
  labs(main = "") +
  ggsave(file =  here::here("images", "Effect_Emotionality.png"), 
         width = 15, height = 10, units = c("cm"),  dpi = 600)
```

```{r dp2_04, message=F, warning=F}
sjPlot::plot_model(m8.glmer, type = "pred", terms = c("Gradability")) +
  theme_bw() +
  theme(legend.position = "top",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black")) +
  scale_y_continuous(name = "Predicted Probabilty of VERY", 
                     limits = c(0, .5),
                     breaks = seq(0, .5, .20), 
                     labels = seq(0, .5, .20)) +
  labs(main = "") +
  ggsave(file =  here::here("images", "Effect_Gradability.png"), 
         width = 15, height = 10, units = c("cm"),  dpi = 600)
```

```{r dp2_04, message=F, warning=F}
sjPlot::plot_model(m8.glmer, type = "pred", terms = c("L1")) +
  theme_bw() +
  theme(legend.position = "top",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black")) +
  scale_y_continuous(name = "Predicted Probabilty of VERY", 
                     limits = c(0, .5),
                     breaks = seq(0, .5, .20), 
                     labels = seq(0, .5, .20)) +
  labs(main = "") +
  ggsave(file =  here::here("images", "Effect_L1.png"), 
         width = 15, height = 10, units = c("cm"),  dpi = 600)
```

```{r verynze_122, message=FALSE, warning=FALSE}
randomtb <- ranef(m8.glmer)
rndmadj <- as.vector(unlist(randomtb$`Adjective`))
adj <- as.vector(unlist(rownames(randomtb$`Adjective`)))
rndmadjtb <- data.frame(adj, rndmadj)
colnames(rndmadjtb) <- c("Adjective", "Intercept")
rndmadjtb <- rndmadjtb[order(rndmadjtb$Intercept, decreasing = T),]
# inspect
head(rndmadjtb)
```

```{r verynze_122, message=FALSE, warning=FALSE}
ggplot(rndmadjtb, aes(Adjective, Intercept)) +
  geom_point(aes(reorder(Adjective, -Intercept, fun = Intercept), y=Intercept)) +
  coord_cartesian(ylim = c(-1.5, 1.5)) +
  theme_set(theme_bw(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15, angle=90),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  scale_x_discrete(breaks = rndmadjtb$Adjective[seq(1,length(rndmadjtb$Adjective),9)]) +
  labs(x = "Adjective type \n(only selected labels displayed)", y = "Adjustment to Intercept") +
  ggsave(file = here::here("images", "RandomEffects_Adjective.png"), 
       height = 5,  width = 7.5,  dpi = 320)
```


```{r verynze_122, message=FALSE, warning=FALSE}
rndmadjtb %>%
  dplyr::filter(Intercept > .5 | Intercept < -.5) %>%
  ggplot(aes(Adjective, Intercept)) +
  geom_point(aes(reorder(Adjective, -Intercept, fun = Intercept), y=Intercept)) +
  coord_cartesian(ylim = c(-1.5, 1.5)) +
  theme_set(theme_bw(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15, angle=90),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
#  scale_x_discrete(breaks = rndmadj_redux$Adjective[seq(1,length(rndmadj_redux$Adjective),9)]) +
  labs(x = "Adjective type \n(only selected labels displayed)", y = "Adjustment to Intercept") +
  ggsave(file = here::here("images", "RandomEffects_Adjective_redux.png"), 
       height = 5,  width = 7.5,  dpi = 320)
```

# Power Analysis

The diagnostics show that the data still do not fit the assumptions of the model very well but the situation has improved but we have to accept this as there is not much we can do. Also, the plot does not take the random effect structure into account which is like to have a very positive impact on the fit as the random intercepts by Adjective explained a significant and substantial amount of variance. We will now perform a power analysis to check if the sample size was sufficient to arrive at robust conclusions.

```{r verynze_103, message=FALSE, warning=FALSE}
# load package
library(simr)
# restructure data
pverywscnew <- verywscnew %>%
  dplyr::select(Age, Emotionality, Adjective, very) %>%
  dplyr::mutate(other = ifelse(very == "very", 0, 1)) %>%
  dplyr::mutate(very = ifelse(very == "very", 1, 0)) %>%
  dplyr::group_by(Age, Emotionality, Adjective) %>%
  dplyr::summarise(very = sum(very), other = sum(other))
# redo model
gm1 <- glmer(cbind(very, other) ~ Age + Emotionality + (1 | Adjective), 
             data = pverywscnew, family = binomial, 
             control = glmerControl(optimizer="bobyqa", 
                                    optCtrl = list(maxIter = 100)))
# set seed for replicability
set.seed(2019121201)
# calculate power for Age
powerSim(gm1, fixed("Age", "lr"), nsim=100)
```

The power analysis confrims that the sample size is not only sufficient but even excessive and would have detected an effect the size of age in 100 percent of cases (lower ci 96.38, higher ci 100). The target is merely a standard of 80 percent in clinical trials!

```{r verynze_104, message=FALSE, warning=FALSE}
# set seed for replicability
set.seed(2019121202)
# calculate power for Emotionality
powerSim(gm1, fixed("Emotionality", "lr"), nsim=100)
```

The power analysis confrims that the sample size is not only sufficient but even excessive and would have detected an effect the size of age in 100 percent of cases (lower ci 96.38, higher ci 100). The target is merely a standard of 80 percent in clinical trials!

We will now check if the sample size is sufficient to detect a small effect (Cohen's d 0.2) - the traditional scale is 0.2 for a small, 0.5 for medium sized, and 0.8 for a large or strong effect. 

To test this, we check if the sample size of the model is sufficient to find a small effect. In order to check what a small effect is, we need to determine the odds ratios of the fixed effects and then convert them into Cohen's d values for which we have associations between traditional denominations (small, medium, and large) and effect sife values. According to @chen2010big odds ratios of 1.68, 3.47, and 6.71 are equivalent to Cohen's d = 0.2 (small), 0.5 (medium), and 0.8 (large).

```{r verynze_105, message=FALSE, warning=FALSE}
estimatesfixedeffects <- fixef(gm1)
exp(estimatesfixedeffects)
```

We will now change the size of the effect of Age20-29 to make it "small", i.e. on the brink of being noise but being just strong enough to be considered small. In other words, we will set the effect so that its odds ratio is exactly 1.68.

```{r verynze_106, message=FALSE, warning=FALSE}
fixef(gm1)["Age20-29"] <- 0.519
estimatesfixedeffects <- fixef(gm1)
exp(estimatesfixedeffects)
```

A small effect size would be equivalent to an estimate of 0.519.

We have now defined the effect size of Age20-29 to be the smallest meaningful effect. We can now test, if the model is powerful enough to detect this small effect with a likelihood high than 80 percent.

```{r verynze_107, message=FALSE, warning=FALSE}
# set seed for replicability
set.seed(2019121202)
fixef(gm1)["Age20-29"] <- 0.519
powerSim(gm1, fixed("Age20-29", "z"), nsim=100)
```

Based on the sample size of the present study, the model would find a small effect only in 46 percent of cases. We will now check with which accuracy the model would find a medium effect (odds ratio of 3.47 or Cohen's d of .5). To do this, we again set set the effect size to the desired medium effect.

```{r verynze_108, message=FALSE, warning=FALSE}
fixef(gm1)["Age20-29"] <- 1.245
estimatesfixedeffects <- fixef(gm1)
exp(estimatesfixedeffects)
```

A medium effect size size would be equivalent to an estimate of 1.245.

```{r verynze_109, message=FALSE, warning=FALSE}
# set seed for replicability
set.seed(2019121203)
fixef(gm1)["Age20-29"] <- 1.245
powerSim(gm1, fixed("Age20-29", "z"), nsim=100)
```

Our model would detect a medium effect in 100 percent of cases. We will now check the effect size at which our model would find an effect with 80 percent accuracy.

```{r verynze_110, message=FALSE, warning=FALSE}
# set seed for replicability
set.seed(2019121204)
fixef(gm1)["Age20-29"] <- 0.68 # 0.68 = 80%; 0.65 = 75%, 0.7 = 84%, 0.8 = 89%
powerSim(gm1, fixed("Age20-29", "z"), nsim=100)
```

Based on the sample size in the present study, the analysis would find a mid-range small effect with an effect size of 1.97 OR (see below) or a 0.68 Estimate with an accuracy of 80 percent. The sample size in this study is thus large and robust enough to detect even mid-range small effects with a sufficient accuracy. Mid and large sized effects are detected in 100 percent of cases given the sample size at hand.

```{r verynze_111, message=FALSE, warning=FALSE}
exp(fixef(gm1))
```

# Tabulation

In a final step, we create a table which shows the sample size at different stages of the analysis. In a first step, we extract the number of adjectives.

```{r verynze_123, message=FALSE, warning=FALSE}
# load data sets
raw <- read.delim("datatables/wscadjdf.txt", sep = "\t", header = T, quote = "\"", skipNul = T)
processed <- read.delim("datatables/ampwsc.txt", sep = "\t", header = T, quote = "\"", skipNul = T)
processed <- processed %>%
  dplyr::select(-AgeNumeric) %>%
  dplyr::mutate(FileSpeaker = paste(File, Speaker, sep = ""))  %>%
  dplyr::mutate(very = ifelse(Variant == "very", "very", "other")) %>%
  na.omit()
statz1 <- read.delim("datatables/ampwsc.txt", sep = "\t", header = T, quote = "\"", skipNul = T)
statz1 <- statz1 %>%
  dplyr::filter(Variant != "0") %>%
  dplyr::select(-AgeNumeric) %>%
  dplyr::mutate(FileSpeaker = paste(File, Speaker, sep = ""))  %>%
  dplyr::mutate(very = ifelse(Variant == "very", "very", "other")) %>%
  na.omit()
cutoff <- 0.007
statz2 <- statz1[-(which(verywsc$cooksdistance > cutoff)),]
# extract number of adjectives
token_raw <- nrow(raw)
token_processed <- nrow(processed)
token_statz1 <- nrow(statz1)
token_statz2 <- nrow(statz2)
# create vector
adjsN <- c(token_raw, token_processed, token_statz1, token_statz2) 
# inspect vector
adjsN
```

Now, we extract the number of speakers.

```{r verynze_124, message=FALSE, warning=FALSE}
# extract number of speakers
speaker_raw <- length(table(paste(raw$File, raw$Speaker, sep = "")))
speaker_processed <- length(table(processed$FileSpeaker))
speaker_statz1 <- length(table(statz1$FileSpeaker))
speaker_stat2 <- length(table(statz2$FileSpeaker))
# create vector
spkrsN <- c(speaker_raw, speaker_processed, speaker_statz1, speaker_stat2) 
# inspect vector
spkrsN
```

Now, we extract the number of amplified slots.

```{r verynze_125, message=FALSE, warning=FALSE}
# extract number of amplified slots
# we first need to determine the number of amplifier slots for the raw data
# vecttor of amplifiers
# define amplifiers
amplifiers <- c("absolutely", "actually", "aggressively", 
                "amazingly", "appallingly", "awful", "awfully", 
                "badly", "bloody", "certainly", "clearly",
                "complete", "dead", "completely", "considerably", 
                "crazy", "decidedly", "definitely",  "distinctly", 
                "dreadfully", "enormously", "entirely", "especially", 
                "exactly", "exceedingly", "exceptionally", 
                "excruciatingly", "extraordinarily", "extremely",
                "fiercely", "firmly", "frightfully", "fucking", 
                "fully", "genuinely", "greatly",
                "grossly", "heavily", "highly", "hopelessly", 
                "horrendously", "hugely",
                "immediately", "immensely", "incredibly", 
                "infinitely", "intensely", "irrevocably",
                "mad", "mega", "mighty", "most", "much", 
                "obviously", "openly", "overwhelmingly", "particularly", 
                "perfectly", "plenty", "positively", "precisely", 
                "pretty", "profoundly", "purely", 
                #"quite", 
                "real", "really", "remarkably", "seriously", 
                "shocking",   "significant", "significantly", "so", 
                "specially", "specifically", "strikingly",
                "strongly", "substantially", "super", "surely", 
                "terribly", "terrifically", 
                #"too",
                "total", "totally", "traditionally", "true", 
                "truly", "ultra", "utterly", "very",
                "viciously", 
                #"well", 
                "wholly", "wicked", "wildly")
raw <- raw %>%
  dplyr::mutate(Variant = str_replace_all(tolower(Variant), "/.*", "")) %>%
  dplyr::mutate(Amplified = ifelse(Variant %in% amplifiers, 1, 0))
# extract number of amplified slots
amp_raw <- sum(raw$Amplified)
amp_processed <- sum(processed$Amplified)
amp_statz1 <- sum(statz1$Amplified)
amp_stat2 <- sum(statz2$Amplified)
# create vector
ampN <- c(amp_raw, amp_processed, token_statz1, token_statz2) 
# inspect vector
ampN
```

Now, we extract the number of amplified slots.

```{r verynze_126, message=FALSE, warning=FALSE}
# create table from results
Table0 <- data.frame(spkrsN, adjsN, ampN) 
Table0 <- Table0 %>%
  dplyr::rename(Speakers = spkrsN, AdjectiveToken = adjsN, 
                AmplifiedAdjectives = ampN) %>%
  dplyr::mutate(Percent = round(AmplifiedAdjectives/AdjectiveToken*100, 1))
rownames(Table0) <- c("raw data",  "processed data", "variable context data", 
                      "variable context data without outliers")
# save table to disc
write.table(Table0, here::here("data", "Table0.txt"), sep = "\t", row.names = T, col.names = T, quote = F)
# inspect vector
Table0
```

We now have to recreate Table 2 bacuse we had to remove outliers during the model fitting.

```{r verynze_127, message=FALSE, warning=FALSE}
# create table
Table2 <- statz2 %>%
  dplyr::select(Age, Gender, FileSpeaker, very)  %>%
  dplyr::group_by(Age, Gender) %>%
  dplyr::summarize(Speakers = length(names(table(FileSpeaker))),
                   AdjectiveSlots = n(),
                   very = table(very)[2]) %>%
  dplyr::mutate(Percent = round(very/AdjectiveSlots*100, 2))
Table2 <- rbind(as.data.frame(Table2), c("", "", sum(Table2$Speakers), 
                  sum(Table2$AdjectiveSlots), 
                  sum(Table2$very), round(mean(Table2$Percent), 2)))
# save data to disc
write.table(Table2, here::here("data", "Table2.txt"), sep = "\t", row.names = F)
# inspect Table2
Table2
```


```{r verynze_128, message=FALSE, warning=FALSE}
Varianttbwsc <- table(processed$Variant)
Varianttbwsc <- Varianttbwsc[order(table(processed$Variant), decreasing = T)]
Variantnames <- as.vector(names(Varianttbwsc))
Variantn <- as.vector(Varianttbwsc)
Variantprcnt <- round(Variantn/sum(Variantn)*100, 2)
Variantprcnt2 <-  c(0, round(Variantn[2:length(Variantn)]/sum(Variantn[2:length(Variantn)])*100, 2))
Table3 <- data.frame(Variantnames, Variantn, Variantprcnt, Variantprcnt2)
colnames(Table3) <- c("Variant", "TokenFrequency", "PercentageSlots", "PercentAgeAmplifiedensifiers")
Table3 <- rbind(Table3, c("Total", sum(as.vector(Table3$TokenFrequency)), 
                          "", ""))
rownames(Table3) <- NULL
# save data to disc
write.table(Table3, here::here("data", "Table3.txt"), sep = "\t", row.names = F)
# inspect data
Table3
```


We have reached the end of the analysis of lexical errors revised incorrectly without corpus data.


# Citation & Session Info {-}

Schweinberger, Martin. `r format(Sys.time(), '%Y')`. *On the waning of forms - a corpus-based analysis of losers in language change (Part 3)*. Brisbane: The University of Queensland. url: https://slcladal.github.io/isle6verynze.html (Version `r format(Sys.time(), '%Y.%m.%d')`).

```
@manual{schweinberger`r format(Sys.time(), '%Y')`isle6verynze,
  author = {Schweinberger, Martin},
  title = {On the waning of forms - a corpus-based analysis of losers in language change (Part 3)},
  note = {https://slcladal.github.io/isle6verynze.html},
  year = {`r format(Sys.time(), '%Y')`},
  organization = {The University of Queensland, School of Languages and Cultures},
  address = {Brisbane},
  edition = {`r format(Sys.time(), '%Y.%m.%d')`}
}
```

```{r fin}
sessionInfo()
```


***

[Back to top](#introduction)


***

# References {-}

